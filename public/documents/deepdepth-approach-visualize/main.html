DeepDepth
      An Approach To Visualize Twitter Tweets
                          AmirSaber Sharifi
                                     October 2014
                                                                                                     

         
                                                                                                     
         Contents
                            1                                                 

         
                                                                                                            
         List of Figures
                            2                                                 

         
                                                                                                            
         Chapter 1
Introduction
1.1   Social Networks
A social network is a structure of relationships linking social actors or the
set of actors and the ties among them[?].   Relationships or ties are the
basic building blocks of human experience, mapping the connections that
individuals have to one another [?][?]. Social Networks are typically defined
as a social structure made up of a set of social actors, who can be individuals
or organizations, and a set of dyadic ties between these actors. Being friends,
relatives or colleges are examples of possible dyadic ties.
     As the world becomes more interconnected through the World Wide
Web, social networks are becoming more relevant through World Wide Web.
When these relations happen through World Wide Web they are called So-
cial Web.  In general, Social Web is a set of relationships that link people
over the World Wide Web[?].  Social Web covers the design and develop of
software or web pages that encourage social interactions using Word Wide
Web.  Examples of some Social Web implementation can be games, educa-
tion and social networking websites.  Facebook, Google Plus, Tumbler and
Twitter can be named as examples of social networking websites.
     Depend on the social networking website, social actors can be individ-
uals, organizations and groups and social dyadic ties between these actors
also depends on the social networking website.  As an example in Twitter,
both individuals and organizations can have accounts and they can interact
with other actors by following others, posting a message, replying to other
actor messages and re-post a message that has been originally posted by
other actor.
     These social networking websites can get benefits to individuals and
organizations.  As an individual, making friends, chatting, posting photos
and having social interactions in general can be expected as a benefit of
a social networking website.   Creating online communities so users with
common interests can join and socialized around the topic or find old school
                                                          3                                                 

         
         CHAPTER 1.  INTRODUCTION                                                    4
         friends on these websites are some other benefits of social web for individuals.
            On the other hand organization can use social networking websites to
         reach their audiences easier.  They can establish communities and pages to
         reach more audiences and even use smart advertisement tools to advertise
         their message to specific group of people. By looking at trends and hit rate
         of their posts they can make better decisions for their future activities or
         products. These are some examples of benefits for organizations while a lot
         more can be imagined using social network websites and related analytic
         tools designed for them.
            Each social network could be analyzed with different perspectives. One
         can be analyzing social network structures to identify patterns and exam-
         ine network dynamics.  The other can be analyzing social network data.
         These data can be the message that a user posts or a color they choose as
         background or even time of the day users are active on social networks.
            Twitter is one of the famous social networking website.  Users in Twit-
         ter can read and post 140 character short messages that are called tweets.
         Twitter provide various ways of posting a tweet like using their web site,
         application or text messages. It&#8217;s established on March 2006 and since then
         it grows fast between users[?]. There are about 284 million active users on
         Twitter.  Users on Twitter post average of 6,000 tweets per second which
         correspond to 350,000 tweets per minute and 500 million tweets per day[?].
         Twitter also supports more than 35 languages. This is a substantial amount
         of data that can be used in different analyses.
            Twitter provides a substantial amount of information of each tweet. In-
         formation like user number of tweets, user profile color, language and etc.
         These information can be useful also. One example can be looking at relation
         between profile color of users and their tweets about committing suicides.
         By implementing an appropriate tool one can analyze Twitter tweets, or any
         other social networking websites, in different perspectives and get useful and
         meaningful results.  For instance by watching and monitoring tweets which
         contains symptoms of a disease over time, origin of a disease could be found
         or even prevent the next possible epidemic.
1.2   DeepDepth
Our goal in this master project is to design a modular platform called Deep-
Depth to provide an infrastructure for analyzing and visualizing social net-
work data. DeepDepth is able to connect to specific sources of social network
data and then be configured to define various analyzes and their required
visualizations.
   Administrator is able to exapand and manage DeepDepth which means
an  administrator  with  knowledge  of  programming  can  add  query  types,
graphs or even new social network source into the platform.  In the first
                                                                                                            

         
         CHAPTER 1.  INTRODUCTION                                                    5
         iteration of the platform, Twitter is considered as the main source of data,
         although other sources can be added to project later.
            Since DeepDepth is a social network related service users are able to login
         using their social network identity or create their own username. DeepDepth
         will help them to access visualized meaningful social network data without
         having vast knowledge of computer science. They are able to tweek results
         to their need. Since using social network websites is growing, various entities
         such as researchers, laboratories and industries found social network websites
         a good resource of information.  Noticing the importance of social network
         websites on our life and benefits that a good analytic tool could give us, idea
         of DeepDepth shaped.
1.3   Related works
Here are some other similar systems available on web that do analytic on
social network data. Some of those systems are as follow:
Orgnet.com SNA   Social Network Analysis (SNA) is a tool that does
mapping and measuring of relationships and flows between actors.  It pro-
vides mathematical and visual analysis of social network and calculate dif-
ferent degrees for each node such as betweenness and closeness.[?]
Twazzup   A monitoring tool to show users each time their keyword is
mentioned in a tweet.[?]
Twitscoop   was a real-time visualization tool that could tank tweet words
based on how frequently they are used.[?]
TweetPsych   is a web application that uses linguistic analysis algorithms
to create a profile for a person based on what they have been tweeted on
Twitter.[?]
Tweeps   analyzes the content of user&#8217;s tweets and make statistic for that
specific user. This service is currently down.[?]
Twitonomy   analyzes activity of a user in twitter. It can gives some gen-
eral numbers like average number of tweets per day or users most mentioned
and active hours and days. [?]
   Most twitter Monitoring and Analytics tool are not working any more
because of Twitter change in their API policy which doesn&#8217;t let third party
apps to have access to all tweets using their API. Companies which want to
have access to all tweets should go into a contract with Twitter[?].
                                                                                                            

         
         CHAPTER 1.  INTRODUCTION                                                    6
            DeapDepth is different from these examples in essence that DeepDepth
         is more general.  It&#8217;s a platform that administrator of it can add graphs,
         query types and etc so users will be able to use different kinds of analytic
         and visualizations.  It&#8217;s more dynamic that means DeepDepth can also get
         connected to different data sources and do analyzes on them.  These data
         sources can be Facebook, Google+ or any other social network in future.
1.4   Challenges
To implement DeepDepth there were some challenges. This challenges hap-
pened in different aspect of project. For instance in gathering data, storing
data, processing data and visualizing the result.
   The first step in analyzing a data is the data and gather it. Since Deep-
Depth is a modular application, it can use any Hive database as it source
of analyzes.  For Twitter scenario gathering data has been done by using
Twitter Official client for developers which is called HBC. It&#8217;s a client for
a stream API that receive a sample of all tweets.  Since HBC should be an
always running process it&#8217;s running in a PaaS named Heroku[?]. Heroku is
also the service that help storing the data using its Treasure Data[?] api.
   Processing data was a challenge that could be handled in various ways.
One can suggest using Apache Storm[?] which results in a real time analysis.
Because of required resources to do real time processing, DeepDepth is using
an on demand processing.   MapReduce is the technique that is used to
process a Hive database entries.
   After the process phase results need to be visualized. To be able to have
a modular application a framework of drawing charts and graphs should
be considered so administrator and developers can later add graphs to the
project easily. So in DeepDepth Visualizing data part is implemented using
D3.JS[?] library which is a graph framework that is able to draw specific
charts and graphs and also can be programmed to draw custom graphs and
charts.  By using D3.Js a lot of ready to use charts are available to use in
DeepDepth and developer or administrator can also add other graph types
to it.
                                                                                                            

         
                                                                                                            
         Chapter 2
DeepDepth_______________________
  &#x2219; Implementation of server and client sides using Test Driven Devel-
        opment                                                                               
2.1   High-Level Description
2.1.1   Components______________________________________________________
 WY: How about combining Chapters 2 and 3 and call it DeepDepth.
 Then, you have a section called &#8221;High-Level Description&#8221;, which is your
 Section 2.1 now, and then you have another section called &#8221;Implemen-
 tation Details&#8221; which has the subsections on Server and Client.  Then,
 within these subsections,  you briefly describe the technology that you
 use, why you chose to use it, and how you use it.
      &#x2219; What are the programmer work space and environment provided for
        this project.
      &#x2219; What are the components in this project and briefly describe them
      &#x2219; How those components are related and how they interact
      &#x2219; Work flow Diagram
      &#x2219; Data flow Diagram
      &#x2219; Use  Cases,  what  are  user  types  and  how  different  users  see  the
        project and how they use this software                                      
                                                          7                                                 

         
         CHAPTER 2.  DEEPDEPTH                                                         8
         2.1.1.1   Major Components
DeepDepth has been made out of 4 major components. Social data collector,
Social data database, Web Application and Web application database.  All
of these components are programmed in a cloud IDE, C9, and are available
to access their code via gitHub.  Figure ?? shows how DeepDepth major
components are connected and how they interact with social networks.
                                            
                 Figure 2.1: How major components are connected
     Social data collector is the application that is responsible of collecting
data from social networks and store them into social data database.  This
can be done in various ways. It can be done by connecting to social network
APIs, crawling their web site, getting streams and etc.  At the same time
Social data collector should saved the retrieved data into a database. Social
data collector is an on going application that should be always working and
gather as much as data possible into database.
     Social data database is the destination of Social data collector for saving
data.  Since social data is a big data, the database should be capable of
storing bulk data and should also be able to run large, complex queries in
an acceptable time. For this reason a database with MapReduce capablities
is a well fitted database.
     After receiving and storing data into database, Web application compo-
nent should enable the platform for users to access the data and run their
own queries against the Social data database. Web application is the com-
ponent that users directly interact with using web protocols.  To maintain
different types of users, status of requested queries and etc Web application
needs to access to a database to store it&#8217;s data.
     Web application database doesn&#8217;t need to ba a bulk database neccesserly.
Since the main process is going to happen on Social data database, Web
application database is only for general information of the application such
as user names, password, query types and etc.
2.1.1.2   Web Appication
Web application is the main component in DeepDepth. Web application is
the component that connects Social data database to users and provide the
required interface for users to submit their queries into database and get
their results back.
     Users are able to register into application by accessing the Web appli-
cation via internet and then sign up there.  Sign up process can be done
                                                                                                            

         
         CHAPTER 2.  DEEPDEPTH                                                         9
         by using existing user services such as Google and Facebook, or by creating
         a local user in Web application.  Figure ?? show how the register process
         works.
                                                     
                               Figure 2.2: Register process
            Web application consider two types of roles, admins and users. Admins
         are the users who have permission to do the required configuration for data
         sources and query types.  Then users can login and select from the defined
         query types and data sources and generate their queries based on their need
         and submit it to database to get results. Figure ?? demonstrate that after
         the user authenticate itself into system their role is assigned to them based
         on database information.
                                                     
                                 Figure 2.3: Login process
            After logging into Web application based on the user role, Web applica-
         tion provide different functionalities for them.  An admin is able to create
         Field types, Graph types and Job types. Each query should have a Job type
         that defines the type of the query, the required fields to run the query and
         the graphs that can be drawn for that query.  When a user choose a Job
         type, Web application would fetch the required Field types and ask the user
         to fill them to be able to run the query.
            The main responisibility of admin is to create and maintain Job types.
         Job types are created of Graph types, Field types, Query pattern and source.
         Source means the database address that the query should be sent to. Field
         types are the required fields that are needed to run the query with. Query
         pattern is the pattern that will genertate the final query based on what
         user puts into fields and the Graph types are the graphs that can be drawn
         based on the chosen Job type. Figure ?? shows the raltion of data between
         entities.
            When an admin logs into DeepDepth, Field types should be defined.
         After defining Field types,  Graph types should be defined.   Using Field
         types and Graph types, Job types could be defiend and users are able to use
         it. Figure ?? shows the use case of admin.
                                                                                                            

         
         CHAPTER 2.  DEEPDEPTH                                                        10
                                                     
       Figure 2.4: Field type, Graph type, Job type and Query relation
                                                     
                               Figure 2.5: Admin use case
2.1.2   Technologies
______________________________________________
     &#x2219; Describe the technology that have been used in this project for each
        component
      &#x2219; More detail into each component and how they interact with each
        other                                                                                  
2.1.2.1  Social data
A Social data collector can be written in various ways.  In initial version
of DeepDepth it&#8217;s uses a Java application which connects to Twitter Filter
endpoint to recieve tweets from Twitter which are filtered based on their
location. The chosen location is mainland of United States. Since it connects
to Filter endpoint it will recieve a sample of tweets which are about 1% of all
tweets in U.S. To be able to have all tweets it needs to connect to Firehose
endpoint of Twitter which is not free for use.  Since this application needs
to be an always running application and connected application, it&#8217;s running
in Heroku PaaS.
   For each tweet that the Social data collector recieve from Twitter stream
it needs to save it to database. DeepDepth is using Treasure Data service to
stores it&#8217;s data. Treasure Data is a company which provides Hive databases
as service. Treasure data can also be used as a plug in into Heroku applica-
tion.  So Social data collector is able to store its recieved tweet into a Hive
database using Treasure Data service.
   Hive is a database that can be queried using a SQL like language named
HiveQL. These queries will be queued and then executed as MapReduce jobs
in Hive.  Query execution time varies based on the query and the number
of processors associated to Treasure Data account.  In the initial version of
DeepDepth only one processor is being used.
                                                                                                            

         
         CHAPTER 2.  DEEPDEPTH                                                        11
         2.1.2.2   Web Application
Web application component of DeepDepth is implemented using MEAN
stack. MEAN stack contains, MongoDB as database, Express.JS as it&#8217;s web
server, Angular.JS for it&#8217;s browser side and Node.JS as the programming
language.
     On the server side, Node.JS has been used which is a javascript based
platform. It&#8217;s hosting Express.JS web framework for web and http requests.
Grunt.JS is used for task automation during building process and debugging
process.  For the Web application to be able to recover from crashes, For-
ever.JS has been used. Since DeepDepth is developed in a Test Driven Envi-
ronment, Should.JS and Phantom.JS are used for testing porposes. JSHint
is also used to make sure of clean Javascript code.  In the build process by
using CSSHint and Uglify.JS, a compact version of required Javascripts and
CSS files are created for the client side.
     On the client side, DeepDepth is using Single Page Application model.
Angular.JS is used to achieve SPA. Jquery is the other Javascript library
used in client side for manipulating and controlling HTML elements. D3.JS
is used to implement and draw graphs and charts.  For User Interface ele-
ments of Web application, Bootstrap is being used. For templating purposes
of application Jade is being used.
     For local data that are needed by Web application, such as Usernames,
Queries, Job Types and etc. DeepDepth is using MongoDB which is a docu-
ment oriented database. On DeepDepth there is a RESTful implementation
of Web API&#8217;s so other future applications would be able to use it as a ser-
vice. To implement the RESTful API on top of the database, Mongoose has
been used.
2.2   Implementation
2.2.1   Server______________________________________________________________
     &#x2219; What is the server side and what it is doing
      &#x2219; How components in server side have been implemented                 
DeepDepth Web Application server side has been made of 4 major com-
ponents.  These 4 components are App, Config, Node Modules and Public.
App is the main component that works on the server side and is reponsible
of recieving requests and replying to request using RESTFul APIs.  Config
is the component that is responsible for required configuration such as port
numbers and then initialize the application with them. Node Modules is the
component that consist of other Node.JS ready to use components. Public
is what a user will get as the result of navigating to DeepDepth application
                                                                                                            

         
         CHAPTER 2.  DEEPDEPTH                                                        12
         using a browser.  Public component is the part that will be considerd is
         client side.
                                     Figure 2.6: DeepDepth server.js____________________________
&#8217;use strict&#8217;;
/**
 * Module dependencies.
 */
var init = require(&#8217;./config/init&#8217;)(),
       config = require(&#8217;./config/config&#8217;),
       mongoose = require(&#8217;mongoose&#8217;);
/**
 * Main application entry file.
 * Please note that the order of loading is important.
 */
// Bootstrap db connection
var db = mongoose.connect(config.db, function(err) {
       if (err) {
              console.error(&#8217;\x1b[31m&#8217;, &#8217;Could not connect to
                  MongoDB!&#8217;);
              console.log(err);
       }
});
// Init the express application
var app = require(&#8217;./config/express&#8217;)(db);
// Bootstrap passport config
require(&#8217;./config/passport&#8217;)();
// Start the app by listening on &#x003C;port&#x003E;
app.listen(config.port);
// Expose app
exports = module.exports = app;
// Logging initialization
console.log(&#8217;MEAN.JS application started on port &#8217; + config.port);___
            On server by using server.js and package.json Node.JS knows how to
         initilize and start the web server.  Figure ?? shows the usage of config in
         server.js file and how the web server get initialized.
            Package.json is the main configuration file for Node.JS that tells the
         Node.JS which modules are required and how to start and stop the applica-
         tion. Figure ?? shows the package.json file in DeepDepth application.
                                                                                                            

         
         CHAPTER 2.  DEEPDEPTH                                                        13
         2.2.1.1   Environments_______________________________________________________
     &#x2219; What are the development environments (Production, Development
        and Test)
      &#x2219; How they have been implemented in this project
      &#x2219; Examples of codes                                                                 
Continues development is considered to be used in DeepDepth. To do that
three environments are considered for DeepDepth. The first environment is
the Production.  Production environment is the one that goes live on the
main Web server that users can access and use the application. Development
environment is the other one that developers can use to write new lines
of codes and add futures to application without disturbing the production
environment. The test environment is the environment that test teams can
use to write test units and test blocks to test any change and any code before
publishing to production environment.
     Each environment is configured to use different basic variables such as
database connection, mailing system and even the deployment server. Figure
?? shows the source code of development environment as an example of
environments.
2.2.1.2   Models________________________________________________________________
     &#x2219; What are Models in this project
      &#x2219; how they are related
      &#x2219; examples of implementation                                                    
Models are entities in the DeepDepth.  Entities such as a user or a query.
In DeepDepth there are 5 main entities.  Fieldtype, Graphtype, Jobtype,
Query and User. These models are implemented using Mongoose Schemas.
By using Mongoose Schemas DeepDepth is able to validate fields, set re-
quired properties for each model and run pre and post validation functions
before saving or updating any of models.  Figure ?? shows the source code
of Jobtype model with a good example of refrencing to other models and
validation.
2.2.1.3   Controllers___________________________________________________________
     &#x2219; what are the controllers
      &#x2219; how they have been implemented                                             
To interact with any of the models, some functions should be implemented.
                                                                                                            

         
         CHAPTER 2.  DEEPDEPTH                                                        14
         To be able to have full control over access to models, DeepDepth is using
         controllers. Controllers are parts of application which define functions that
         are available for each model and how that function process the model. Us-
         ing controllers, maintaining models and their integrity is easier.  For each
         model there is a controller and for every model that wants to interact with
         another model it should go through their controllers.  Examples of func-
         tions that are implemented in controllers are create, read, update, delete,
         list, hasAutorization and etc. For instance hasAuthorization is the function
         that is authorize users to work with models or their instances.  Using this
         function is neccessary to implement application security and object policies.
         Figure ?? shows three function of Fieldtype controller. These functions are
         responsible to provide delete, list and authorization interface for Fieldtype
         model.
2.2.1.4  Routes
___________________________________________________
     &#x2219; What are server routes
      &#x2219; How my code handle routes                                                     
DeepDepth provides a RESTFul API to access models.   This features is
implemented by handling HTTP requests that are GET, POST, PUT and
DELETE. Routes are the addresses that web server provides that are able
to recieve HTTP requests and perform actions on models.  These actions
are done by calling controller functions.  In figure ?? HTTP requirests and
their address are defined for Query model.  Using middleware approach of
controllers implementation, routes are able to call various functions for each
HTTP request.  These middlewares also help to put access restrictions on
some routes and required login and authorization for them. Using these ap-
proach some routes can be restricted to admins and some to users and some
to public. Routes are also used by the client side. That means DeepDepth
can be used as a service also and many other applications and services could
be created using DeepDepth services.
2.2.1.5  Tasks
_____________________________________________________
     &#x2219; how tasks are implemented in deepdepth                                   
DeepDepth requires to perform some routine tasks in intervals. One exam-
ple for those tasks is to check status of submitted queries in Social Data
database. These tasks are CronJobs that are defined in DeepDepth. Devel-
opers can add other Tasks into DeepDepth. Figure ?? is the source code of
the task that check the status of queries in database every 10 seconds. It&#8217;s
been done by using Query controllers to access their status and updating
them.
                                                                                                            

         
         CHAPTER 2.  DEEPDEPTH                                                        15
         2.2.1.6   Tests___________________________________________________________________
     &#x2219; Test types implemented for server side
      &#x2219; how they are implemented                                                      
DeepDepth is using Should.JS and Karma.JS to implement testing blocks
of application.  On the server side before writing each model failing tests
are written. This approach is called Test Driven Development. That means
a test and it&#8217;s requirements are coded first before having the module and
then the module is programmed to meet the test requirements. DeepDepth
is doing unit testing for each module and developers are able to add to unit
tests by editting each module test file.
2.2.2   Client______________________________________________________________
     &#x2219; Client side implementation                                                      
On the client side of DeepDepth web application, HTML, CSS and Javascript
are used. It consists of distribution version of CSS and Javascript files which
are uglified version of them, library files such as Angular.JS, jQuery and etc.
It also has modules which are the client interface to interact with server side
services and their required HTML implementation.
2.2.2.1   Modules______________________________________________________________
     &#x2219; what are the modules on client side                                          
Modules are packaged versions of models in client side.  Every model on
server side has a module on client side which define how to show the module,
what are it&#8217;s configuration and services that this module can use to access
routes.  There is also a core module which is responsible for general aspect
of client side application such as menu and it&#8217;s items.
2.2.2.2   Config_________________________________________________________________
     &#x2219; how configuration of modules programmed                                 
For each module in DeepDepth, Menu items and it routes should be defined.
Menu item configuration set the menu items for that module and wheter it
should be shown to user or not based on user role.  Since DeepDepth is a
single page application, routes are defined for each module to show different
HTML results in case of viewing, editing or creating a new instance of each
model. By using routes addresses can be human readable and also easier to
copy and reuse in future by pasting them into browser address bar.
                                                                                                            

         
         CHAPTER 2.  DEEPDEPTH                                                        16
         2.2.2.3   Services_______________________________________________________________
     &#x2219; describe client side services implemented for models                     
By defining factories and resources components of Angular.JS, server REST-
Ful APIs are connected to client side.  Since RESTFul APIs of DeepDepth
are defined in standard version,  this approach enables the developers of
DeepDepth to easily manage models from modules of client side and have
two way integration of data and services.
2.2.2.4   Views_________________________________________________________________
     &#x2219; implementation of CRUD views for different modules                   
Each module has a Create,  Read,  Update and Delete functionality.   For
users and admins to be able to interact with DeepDepth, these functions
are presented in HTML form.  Developers create a HTML form for each
action and connects it to its routes using routes configuration.
2.2.3   Example
In this section an example of working with DeepDepth is demonstrated.
DeepDepth is accessible via browsers by navigating to http://deepdepth.amir.ninja.
Users can register, login, manage and submit queries using this interface.
Figure ?? shows the home page of DeepDepth before registering or logging
into software
2.2.3.1   Register and Login
The user can register it self into DeepDepth by visiting sign up page. Figure
?? shows that a user can sign up using his social accounts such as Facebook
and Twitter or create a new Login in DeepDepth.  Users are able to link
their accounts to their social network accounts later in their profile settings.
     After Registring into system users are able to login into system. Figure
?? shows the Sign in page.
2.2.3.2   Main Menu
After signing into DeepDepth, based on the user role in system, they will see
different menu items.  Considering an admin user loging into system figure
?? shows the availbale menu item for admins.
     Each model in application has two menu items.  Listing model items
and creating a new item. By hovering mouse on each menu item, sub menu
items can be seen.  As an example considering Field types, by clicking on
&#8217;List Fieldtypes&#8217;, list of created Fieldtypes will be shown.  Figure ?? and
figure ?? shows listing and creating interface for Fieldtypes.
                                                                                                            

         
         CHAPTER 2.  DEEPDEPTH                                                        17
            By clickin on each item in listing,  more details will be shown.   Also
         editing and deleting each item is availble while viewing the item. Figure ??
         and ?? show the interface for viewing and editing a FieldType.  As it can
         bee seen, in viewing a Fieldtype two buttons are available to edit or delete
         that item.
2.2.3.3  Query
Query menu is the menu which is shared between admins and users.  To
submit a new Query a user should login to DeepDepth and go to New
Query interface by choosing it from menu Items.  Then a unique name for
the query should be chosen.  Another required field is the Jobtype.  Based
on the availble Jobtypes and users requirements, Jobtype should be chosen.
Afterwards a list of required Fields for that Jobtype will be shown that
user should fill them to be able to submit the query.  Figure ?? shows a
query getting created.  As it can bee seen in the figure, selected Jobtype is
Twitter over Time and required field are filled using Ebola keyword and a
time frame.
   After submiting the query user should wait for the data to get collected
from Social network database. By visiting the created query page status of
the query can be checked. When the required processes are done the status
will be changed to success and user can choose from the Graphtypes, the
graph that is desired to view. Figure ?? shows one Graphtype for the Ebola
query. It shows states of U.S. which are talking about Ebola over time and
by clicking on the play button it will go through days and shows how it
changes over time.
                                                                                                            

         
         CHAPTER 2.  DEEPDEPTH                                                        18
                                   Figure 2.7: DeepDepth package.json__________________________
{
  "name": "deepdepth",
  "description": "Full-Stack JavaScript with MongoDB, Express,
      AngularJS, and Node.js",
  "version": "0.0.1",
  "author": "AmirSaber Sharifi",
  "engines": {
    "node": "0.10.x",
    "npm": "1.4.x"
  },
  "scripts": {
    "start": "grunt",
    "test": "grunt test",
    "postinstall": "bower install --config.interactive=false"
  },
  "dependencies": {
    "express": "~4.7.2",
    "express-session": "~1.7.2",
    "body-parser": "~1.5.2",
    "cookie-parser": "~1.3.2",
    "compression": "~1.0.9",
    "method-override": "~2.1.2",
    "morgan": "~1.2.2",
    "connect-mongo": "~0.4.1",
    "connect-flash": "~0.1.1",
    "helmet": "~0.4.0",
    "consolidate": "~0.10.0",
    "swig": "~1.4.1",
    "mongoose": "~3.8.8",
    "passport": "~0.2.0",
    "lodash": "~2.4.1",
    "forever": "~0.11.0",
    "bower": "~1.3.8",
    "grunt-cli": "~0.1.13",
    "glob": "~4.0.5",
    "async": "~0.9.0",
    "nodemailer": "~1.1.1",
    "request": "~2.40.0",
    "cron": "~1.0.4"
  },
  "devDependencies": {
    "supertest": "~0.13.0",
    "should": "~4.0.4",
    "grunt-env": "~0.4.1",
    "load-grunt-tasks": "~0.6.0",
    "karma": "~0.12.0",
    "karma-phantomjs-launcher": "~0.1.2"
  }
}____________________________________________________________________
                                                                              

         
         CHAPTER 2.  DEEPDEPTH                                                        19
                                 Figure 2.8: DeepDepth development.js________________________
&#8217;use strict&#8217;;
module.exports = {
       db: process.env.MONGODB_DEEPDEPTH_DEV,
       app: {
              title: &#8217;DeepDepth - Development Environment&#8217;
       },
       facebook: {
              clientID: process.env.FACEBOOK_ID || &#8217;APP_ID&#8217;,
              clientSecret: process.env.FACEBOOK_SECRET ||
                  &#8217;APP_SECRET&#8217;,
              callbackURL:
                  &#8217;http://localhost:3000/auth/facebook/callback&#8217;
       },
       twitter: {
              clientID: process.env.TWITTER_KEY || &#8217;CONSUMER_KEY&#8217;,
              clientSecret: process.env.TWITTER_SECRET ||
                  &#8217;CONSUMER_SECRET&#8217;,
              callbackURL:
                  &#8217;http://localhost:3000/auth/twitter/callback&#8217;
       },
       google: {
              clientID: process.env.GOOGLE_ID || &#8217;APP_ID&#8217;,
              clientSecret: process.env.GOOGLE_SECRET ||
                  &#8217;APP_SECRET&#8217;,
              callbackURL:
                  &#8217;http://localhost:3000/auth/google/callback&#8217;
       },
       linkedin: {
              clientID: process.env.LINKEDIN_ID || &#8217;APP_ID&#8217;,
              clientSecret: process.env.LINKEDIN_SECRET ||
                  &#8217;APP_SECRET&#8217;,
              callbackURL:
                  &#8217;http://localhost:3000/auth/linkedin/callback&#8217;
       },
       github: {
              clientID: process.env.GITHUB_ID || &#8217;APP_ID&#8217;,
              clientSecret: process.env.GITHUB_SECRET ||
                  &#8217;APP_SECRET&#8217;,
              callbackURL:
                  &#8217;http://localhost:3000/auth/github/callback&#8217;
       },
       mailer: {
              from: process.env.MAILER_FROM || &#8217;MAILER_FROM&#8217;,
              options: {
                      service: process.env.MAILER_SERVICE_PROVIDER
                         || &#8217;MAILER_SERVICE_PROVIDER&#8217;,
                      auth: {
                             user: process.env.MAILER_EMAIL_ID ||
                                 &#8217;MAILER_EMAIL_ID&#8217;,
                             pass: process.env.MAILER_PASSWORD ||
                                 &#8217;MAILER_PASSWORD&#8217;
                      }
              }
       }
};___________________________________________________________________

         
         CHAPTER 2.  DEEPDEPTH                                                        20
                                Figure 2.9: DeepDepth Jobtype Schema_______________________
&#8217;use strict&#8217;;
/**
 * Module dependencies.
 */
var mongoose = require(&#8217;mongoose&#8217;),
       Schema = mongoose.Schema;
/**
 * Validation functions
 */
var validateArrayLength = function(value) {
       return value.length &#x003E; 0;
};
/**
 * Jobtype Schema
 */
var JobtypeSchema = new Schema({
       name: {
              type: String,
              default: &#8217;&#8217;,
              required: &#8217;Please fill Job Type name&#8217;,
              trim: true,
              unique: true
       },
       address: {
              type: String,
              required: &#8217;Please fill Job Type address&#8217;,
              trim: true
       },
       fields: [{
              type: Schema.Types.ObjectId,
              ref: &#8217;Fieldtype&#8217;
       }],
       graphs: [{
              type: Schema.Types.ObjectId,
              ref: &#8217;Graphtype&#8217;
       }],
       queryPattern:{
              type: String,
              default: &#8217;&#8217;,
              required: &#8217;Please fill Job Type Query Pattern&#8217;,
              trim: true
       }
});
mongoose.model(&#8217;Jobtype&#8217;,
    JobtypeSchema).schema.path(&#8217;fields&#8217;).validate(validateArrayLength,
    &#8217;Please add at least one field&#8217;);
mongoose.model(&#8217;Jobtype&#8217;,
    JobtypeSchema).schema.path(&#8217;graphs&#8217;).validate(validateArrayLength,
    &#8217;Please add at least one graph&#8217;);________________________________
                                                                              

         
         CHAPTER 2.  DEEPDEPTH                                                        21
                       Figure 2.10: DeepDepth Fieldtype controller function______________
/**
 * Delete an Fieldtype
 */
exports.delete = function(req, res) {
       var fieldtype = req.fieldtype ;
       fieldtype.remove(function(err) {
              if (err) {
                      return res.status(400).send({
                             message:
                                 errorHandler.getErrorMessage(err)
                      });
              } else {
                      res.jsonp(fieldtype);
              }
       });
};
/**
 * List of Fieldtypes
 */
exports.list = function(req, res) {
    Fieldtype.find().sort(&#8217;-created&#8217;).populate(&#8217;user&#8217;,
    &#8217;displayName&#8217;).exec(function(err, fieldtypes) {
              if (err) {
                      return res.status(400).send({
                             message:
                                 errorHandler.getErrorMessage(err)
                      });
              } else {
                      res.jsonp(fieldtypes);
              }
       });
};
/**
 * Fieldtype authorization middleware
 */
exports.hasAuthorization = function(req, res, next) {
       if (req.fieldtype.user.id !== req.user.id) {
              return res.status(403).send(&#8217;User is not authorized&#8217;);
       }
       next();
};___________________________________________________________________
                                                                              

         
         CHAPTER 2.  DEEPDEPTH                                                        22
                                 Figure 2.11: DeepDepth Query Routes________________________
&#8217;use strict&#8217;;
module.exports = function(app) {
       var users = require(&#8217;../../app/controllers/users&#8217;);
       var queries = require(&#8217;../../app/controllers/queries&#8217;);
       var queryTask = require(&#8217;../../app/tasks/queries&#8217;);
       // Queries Routes
       app.route(&#8217;/queries&#8217;)
              .get(queries.list)
              .post(users.requiresLogin, queries.create);
       app.route(&#8217;/queries/:queryId&#8217;)
              .get(queries.read)
              .put(users.requiresLogin, queries.hasAuthorization,
                  queries.update)
              .delete(users.requiresLogin,
                  queries.hasAuthorization, queries.delete);
       // Finish by binding the Query middleware
       app.param(&#8217;queryId&#8217;, queries.queryByID);
};___________________________________________________________________
                                                                              

         
         CHAPTER 2.  DEEPDEPTH                                                        23
                                  Figure 2.12: DeepDepth Query Task_________________________
&#8217;use strict&#8217;;
/*
 *Module Dependencies
 */
var mongoose = require(&#8217;mongoose&#8217;),
    CronJob = require(&#8217;cron&#8217;).CronJob,
    queries = require(&#8217;../../app/controllers/queries&#8217;),
    request = require(&#8217;request&#8217;),
    config = require(&#8217;../../config/config&#8217;);
//Create and run a task every 10 seconds
new CronJob(&#8217;*/10 * * * * *&#8217;, function() {
    var req = {},
       res = {};
    queries.findIncompletes(req, res, function(err) {
       if (err) {
           console.log(err);
       }
       else {
           req.queries.forEach(function(query) {
              //TODO fix it into database and jobtype
              var statusAddress =
                  query.job.address.replace(&#8217;issue/hive/twitter_db&#8217;,
                  &#8217;status/&#8217;);
              request({
                  uri: statusAddress + query.dbJobId,
                  method: &#8217;GET&#8217;,
                  headers: {
                      &#8217;AUTHORIZATION&#8217;: &#8217;TD1 &#8217; + config.td
                  }
              }, function(err, response, body) {
                  if (err) {
                      console.log(err);
                  }
                  else {
                      body = JSON.parse(body);
                      query.status = body.status;
                      queries.updateStatus(query, function(err,
                         result, raw) {
                         if (err) {
                             console.log(err);
                         }
                      });
                  }
              });
           });
       }
    });
}, null, true);______________________________________________________
                                                                              

         
         CHAPTER 2.  DEEPDEPTH                                                        24
                                                     
                          Figure 2.13: DeepDepth Home Page
                                                     
                            Figure 2.14: DeepDepth Sign Up
                                                     
                            Figure 2.15: DeepDepth Sign in
                                                     
                        Figure 2.16: DeepDepth Admin Menu
                                                     
                       Figure 2.17: DeepDepth List Field type
                                                     
                       Figure 2.18: DeepDepth New Field type
                                                     
                      Figure 2.19: DeepDepth View Field type
                                                                                                            

         
         CHAPTER 2.  DEEPDEPTH                                                        25
                                                     
                       Figure 2.20: DeepDepth Edit Field type
                                                     
                        Figure 2.21: DeepDepth Create Query
                                                     
                         Figure 2.22: DeepDepth View Query
                                                                                                            

         
                                                                                                            
         Chapter 3
Summary and Future Works_
 WY: This part is definitely needed.  It basically summarizes what your
 system is about, why you think it is cool, and you can add future work
 here. Also, List of Figures is usually before Chapter 1 right in front of the
 document.
      &#x2219; Talking about summary of project and it&#8217;s achievements(I am not
        sure if this part is needed or what should I put in here.)
      &#x2219; How this projects can be improved in future
      &#x2219; nice to have features                                                              
DeepDepth is a platform that helps users to analyze social networks and
see graphs and analysis based on their need.  On the other hand it provide
the required infrastructure to developers and admins to add more features
and data sources into DeepDepth. The first version of DeepDepth provides
Twitter U.S. tweets as its datasource and two Jobtypes as example. Because
of having the required infrastructure admins and developers can add more
datasources, Jobtypes and Graphs into system.
     In future, DeepDepth can be improved by getting connected to realtime
data analytic systems such as Apache Storm.  So users will be able to get
analysis without waiting for the MapReduce job to be finished.
     Another feature that can be added in next releases is that to enable
users to ask admin for their desired Jobtype and Graphs.  So admins will
be notified on users needs and create them.  Being able to share results on
Social Networks and downloading Graphs for future use is another nice to
have feauture in future of DeepDepth.
                                                         26                                                

         
                                                                                                            
         Bibliography
[1] Social Network Analysis Methods and Applications, Stanley Wasserman,
     University of Illinois,  Katherine Faust,  University of South Carolina,
     November 1994
[2] Pescosolido, B. 1991. &#8221;The Sociology of the Professions and the Profes-
     sion of Sociology:  Professional Responsibility, Teaching, and Graduate
     Training.&#8221; Teaching Sociology 19:351-361 (special issue on the state of
     graduate education).
[3] BERNICE A. PESCOSOLIDO http://www.uk.sagepub.com/leonguerrero4e/study/materials/reference/05434_socnet.pdf
   THE SOCIOLOGY OF SOCIAL NETWORKS
[4] Halpin, Harry; Tuffield, Mischa. &#8221;A Standards-based, Open and Privacy-
    aware Social Web&#8221; W3C Social Web Incubator Group Report 6th De-
     cember 2010 Report. W3C Incubator Group Report. Retrieved 6/8/2011
[5] http://www.internetlivestats.com/twitter-statistics/
[6] https://about.twitter.com/company
[7] http://www.orgnet.com/sna.html
[8] http://www.twazzup.com/
[9] http://twitscoop.com/
[10] http://tweetpsych.com/
[11] http://www.tweeps.com/
[12] http://www.twitonomy.com/
[13] http://www.brightplanet.com/2013/06/twitter-firehose-vs-twitter-api-whats-the-difference-and-why-should-you-care/
[14] https://www.heroku.com/
[15] http://www.treasuredata.com/
[16] https://storm.apache.org/
[17] http://d3js.org/
                                       27                                                


